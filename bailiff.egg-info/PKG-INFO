Metadata-Version: 2.4
Name: bailiff
Version: 0.1.0
Summary: Foundational scaffolding for the B.A.I.L.I.F.F. fairness evaluation harness.
Author-email: "B.A.I.L.I.F.F. Team" <placeholder@uwo.ca>
License: Proprietary
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.24
Requires-Dist: pandas>=2.0
Requires-Dist: scipy>=1.10
Requires-Dist: statsmodels>=0.14
Requires-Dist: pydantic>=2.5
Requires-Dist: pydantic-settings>=2.1
Requires-Dist: pyyaml>=6.0
Requires-Dist: python-dotenv>=1.0
Requires-Dist: tqdm>=4.66
Provides-Extra: agent
Requires-Dist: openai>=1.40; extra == "agent"
Requires-Dist: anthropic>=0.34; extra == "agent"
Requires-Dist: groq>=0.9; extra == "agent"
Requires-Dist: google-generativeai>=0.7; extra == "agent"
Provides-Extra: analysis
Requires-Dist: matplotlib>=3.8; extra == "analysis"
Requires-Dist: seaborn>=0.13; extra == "analysis"
Requires-Dist: plotnine>=0.12; extra == "analysis"

# B.A.I.L.I.F.F. — Bias Analysis in Interactive Legal Intelligence & Fairness Framework

This repository implements a reproducible harness for auditing fairness in interactive, role‑governed legal mini‑trials powered by LLMs. It supports paired counterfactual trials, structured logs, and analysis‑ready metrics for both outcomes (e.g., conviction) and procedure (e.g., byte share, objections, interruptions, tone).

## Features
- Multi‑agent trial simulation with roles: judge, prosecution, defense
- Paired cue toggling (control/treatment) with blocked randomization
- Budgets/guards: per‑role byte caps, per‑phase message caps, judge blinding
- Structured logs with event tags (objections, interruptions, safety)
- Metrics: paired McNemar log‑odds, flip rate, byte share, measurement‑error correction, basic tone utilities
- Extensible backends: Echo (offline), Groq, Gemini; open‑source adapters are easy to add

## Quickstart
1. Create a virtual environment and install:
   - `python -m venv .venv && .venv\Scripts\activate` (Windows) or `source .venv/bin/activate`
   - `pip install -e .[analysis,agent]`
2. (Optional) Set API keys: `GROQ_API_KEY`, `GOOGLE_API_KEY`
3. Run a pilot pair and write logs:
   - Echo: `python scripts/run_pilot_trial.py --config configs/pilot.yaml --backend echo --out trial_logs.jsonl`
   - Groq: `python scripts/run_pilot_trial.py --config configs/pilot.yaml --backend groq --model llama3-8b-8192 --out trial_logs.jsonl`
   - Gemini: `python scripts/run_pilot_trial.py --config configs/pilot.yaml --backend gemini --model gemini-1.5-flash --out trial_logs.jsonl`

## Repository Layout
- `bailiff/core`: State machine, config, logging, session engine, JSONL I/O
- `bailiff/agents`: Agent abstractions, prompts, optional Groq/Gemini backends
- `bailiff/datasets`: Case templates and cue catalogs
- `bailiff/orchestration`: Randomization and pipelines for paired trials
- `bailiff/metrics`: Outcome and procedural metrics/utilities
- `bailiff/analysis`: Lightweight statistical helpers
- `scripts/`: CLI entry points (pilot runner)
- `docs/`: User guide and API reference

## Learn More
- Design overview and diagrams: `DESIGN.md`
- User guide (install, run, add case/cue/backend, analysis): `docs/USER_GUIDE.md`
- API reference (core modules): `docs/API.md`

## FAQ
- How do I add a new case? Create a YAML under `bailiff/datasets/cases/` with `summary`, `facts`, `witnesses`, and `cue_slots`. See the user guide.
- How do I add a cue? Extend `cue_catalog()` in `bailiff/datasets/templates.py`.
- How do I analyze results? Export JSONL from the runner and follow the analysis examples in `docs/USER_GUIDE.md`.

